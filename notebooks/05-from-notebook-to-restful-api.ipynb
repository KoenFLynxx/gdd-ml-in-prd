{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4b1fef7",
   "metadata": {},
   "source": [
    "> #### Exercise: From Notebook to CLI\n",
    ">\n",
    "> Your favorite Data Scientist created a model that can predict outcome types.\n",
    ">\n",
    "> We have a CLI, but a different model serving pattern is required: a RESTful API.\n",
    "> The API should accept a CSV via the route `/api/v1/predict/` and return a CSV with predictions.\n",
    "> \n",
    "> Run the FastAPI app with the following command:\n",
    ">\n",
    "> ```bash\n",
    "> poetry run uvicorn app.app:app --reload\n",
    "> ```\n",
    ">\n",
    "> * Edit the file app/app.py so that returns predictions. Use the cells below to POST a CSV and checkout the response.\n",
    ">   * Note: we already parsed the incoming CSV into a DataFrame and turned the outgoing DataFrame in a valid response.\n",
    "> * Its inefficient to load the model at every request: can you make sure it's only loaded on startup?\n",
    "> * Bonus: We'd like an endpoint to retrain the model given a CSV that is POSTed. Add an endpoint `/api/v1/train`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65137eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from io import BytesIO\n",
    "\n",
    "import requests\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8df5c05",
   "metadata": {},
   "source": [
    "## Ping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c877d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get('http://localhost:8000/api/v1/ping/')\n",
    "response.raise_for_status()\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a7b006",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cc32bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_csv = \"../data/test.csv\"\n",
    "\n",
    "files = {'file': open(test_csv,'rb')}\n",
    "\n",
    "response = requests.post('http://localhost:8000/api/v1/predict/', files=files)\n",
    "\n",
    "response.raise_for_status()\n",
    "response.content\n",
    "\n",
    "predictions = pd.read_csv(BytesIO(response.content))\n",
    "predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
